# ğŸ“Š Limpieza y TransformaciÃ³n de Datos â€“ Google Colab  

Este repositorio contiene unos **Notebook en Google Colab** donde se realiza un proceso detallado de **limpieza y transformaciÃ³n de datos** antes de su uso en minerÃ­a de datos. La calidad de los datos es clave para garantizar un anÃ¡lisis preciso y modelos efectivos.  

---

## âœ¨ Objetivos  

âœ… Identificar y manejar valores nulos y atÃ­picos para evitar sesgos en el anÃ¡lisis.  
âœ… Corregir errores en los datos como formatos incorrectos o valores inconsistentes.  
âœ… Estandarizar y transformar variables para mejorar la coherencia del dataset.  
âœ… Aplicar tÃ©cnicas de codificaciÃ³n (**One-Hot Encoding, Label Encoding**) si es necesario.  
âœ… Detectar y eliminar datos duplicados para evitar redundancias.  
âœ… Verificar la distribuciÃ³n de los datos y ajustar si es necesario (**log transform, Box-Cox**).  
âœ… **Generar la vista minable**, es decir, el dataset listo para su uso en minerÃ­a de datos.  

---

## ğŸ› ï¸ TecnologÃ­as utilizadas  

- **Python** (pandas, numpy, seaborn, matplotlib, scikit-learn)  
- **Google Colab**  

---

## ğŸ“Œ Pasos realizados en el Notebook  

### ğŸ“¥ 1. Carga de datos  
- Se carga el dataset desde su fuente original (**CSV**).  
- Se revisa la estructura de los datos y se convierten a un formato adecuado.  

### ğŸ” 2. AnÃ¡lisis exploratorio inicial (EDA)  
- **Resumen estadÃ­stico** de las variables numÃ©ricas y categÃ³ricas.  
- **RevisiÃ³n de datos faltantes** y su impacto en el anÃ¡lisis.  
- **IdentificaciÃ³n de valores inconsistentes o errÃ³neos**.  

### âš ï¸ 3. Manejo de valores nulos  
- **Estrategias de imputaciÃ³n**:  
  - Para variables numÃ©ricas: **media, mediana o interpolaciÃ³n**.  
  - Para variables categÃ³ricas: **moda o categorÃ­a "desconocida"**.  
- EliminaciÃ³n de filas o columnas si el porcentaje de valores nulos es alto.  

### ğŸ“‰ 4. DetecciÃ³n y tratamiento de valores atÃ­picos  
- Uso de tÃ©cnicas como el **rango intercuartÃ­lico (IQR)** y **z-score**.  
- Opciones: **eliminaciÃ³n, transformaciÃ³n o reemplazo por valores ajustados**.  

### ğŸ”„ 5. CorrecciÃ³n de datos errÃ³neos  
- **ConversiÃ³n de tipos de datos** (ej. strings a fechas, enteros a flotantes).  
- **NormalizaciÃ³n de formatos** (ej. fechas, texto en minÃºsculas, eliminaciÃ³n de espacios).  

### ğŸ·ï¸ 6. Transformaciones necesarias  
- **One-Hot Encoding** para variables categÃ³ricas.  
- **Label Encoding** si es adecuado para modelos especÃ­ficos.  
- **Mapeo de valores** para categorÃ­as con errores ortogrÃ¡ficos o formatos diferentes.  

### ğŸ“Š 7. VerificaciÃ³n y reducciÃ³n de dimensionalidad  
- EliminaciÃ³n de **columnas irrelevantes o redundantes**.  
- AnÃ¡lisis de **correlaciÃ³n** para evitar multicolinealidad.  
- AplicaciÃ³n de **PCA (opcional)** para reducir dimensiones si el dataset es grande.  

### ğŸ”€ 8. Manejo de datos duplicados  
- **IdentificaciÃ³n y eliminaciÃ³n** de filas duplicadas para evitar sesgos.  

### ğŸ”§ 9. Ajuste de la distribuciÃ³n de datos (si es necesario)  
- **TransformaciÃ³n logarÃ­tmica** para datos sesgados positivamente.  
- **Box-Cox transformation** para normalizar distribuciones.  

### ğŸ“¤ 10. GeneraciÃ³n de la vista minable  
- **ExportaciÃ³n del dataset limpio** en un nuevo archivo listo para el anÃ¡lisis.  
